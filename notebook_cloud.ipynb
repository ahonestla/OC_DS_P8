{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Set up"]},{"cell_type":"markdown","metadata":{},"source":["Python librairies imports :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# File system management\n","import os\n","from pathlib import Path\n","import io\n","\n","# Data manipulation\n","import numpy as np\n","import pandas as pd\n","from typing import Iterator\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Image manipulation\n","from PIL import Image\n","\n","# Dimension reduction\n","from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA\n","\n","# Tensorflow\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras import Model\n","\n","# Pyspark\n","from pyspark.ml.feature import PCA as pyPCA\n","from pyspark.ml.functions import array_to_vector\n","from pyspark.sql import functions as F\n","from pyspark.sql import SparkSession\n","\n","%matplotlib inline\n","sns.set_theme(palette=\"Set2\")"]},{"cell_type":"markdown","metadata":{},"source":["Define work location :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Current project path\n","PATH_PROJ = \"gs://bucket-openclassrooms-p8\"\n","\n","\n","# Define images paths\n","PATH_DATA = PATH_PROJ + \"/data/training\"\n","PATH_RESULTS = PATH_PROJ + \"/data/results\""]},{"cell_type":"markdown","metadata":{},"source":["# Data processing"]},{"cell_type":"markdown","metadata":{},"source":["## Functions"]},{"cell_type":"markdown","metadata":{},"source":["### MobileNetV2 model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model_create(show_summary=False):\n","    \"\"\"Create a MobileNetV2 model with top layer removed\n","\n","    Returns:\n","        MobileNetV2 model\n","    \"\"\"\n","    # Load default model\n","    model_base = MobileNetV2(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n","\n","    # Freeze layers\n","    for layer in model_base.layers:\n","        layer.trainable = False\n","\n","    # Create model without top layer\n","    model_new = Model(inputs=model_base.input, outputs=model_base.layers[-2].output)\n","\n","    # Show model summary\n","    if show_summary is True:\n","        print(model_new.summary())\n","\n","    return model_new"]},{"cell_type":"markdown","metadata":{},"source":["### Images preprocesssing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(content):\n","    \"\"\"Preprocesses raw image bytes.\n","\n","    Args:\n","        content: PIL Image\n","\n","    Returns:\n","        Numpy array\n","    \"\"\"\n","    img = Image.open(io.BytesIO(content)).resize([224, 224])\n","    arr = img_to_array(img)\n","    return preprocess_input(arr)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def featurize_series(model, content_series):\n","    \"\"\"Featurize a pd.Series of raw images using the input model.\n","\n","    Args:\n","        model: CNN model\n","        content_series: pd.Series of image data\n","\n","    Returns:\n","        pd.Series of image features\n","    \"\"\"\n","    content_input = np.stack(content_series.map(preprocess))\n","    preds = model.predict(content_input)\n","    # For some layers, output features will be multi-dimensional tensors.\n","    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n","    output = [p.flatten() for p in preds]\n","    return pd.Series(output)"]},{"cell_type":"markdown","metadata":{},"source":["## Distributed model inference"]},{"cell_type":"markdown","metadata":{},"source":["### Create the Spark session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["23/03/08 15:39:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://nc-ass-vip.sdv.fr:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>oc_p8</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x28815a0b0>"]},"metadata":{},"output_type":"display_data"}],"source":["# Spark session created by cloud notebook\n","\n","# Create sparkContext\n","sc = spark.sparkContext\n","\n","# Set log level\n","sc.setLogLevel(\"ERROR\")\n","\n","spark"]},{"cell_type":"markdown","metadata":{},"source":["### Broadcast the model weights"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_with = model_create()\n","model_without = model_create(freeze_layers=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create broadcast weights\n","broadcast_weights = spark.sparkContext.broadcast(model_create(show_summary=True).get_weights())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@F.pandas_udf(\"array<float>\")\n","def featurize_udf(content_series_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n","    \"\"\"This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n","        The decorator specifies this returns a Spark DataFrame column of type ArrayType(FloatType).\n","\n","    Args:\n","        content_series_iter: Iterator over batches of data, where each batch\n","                            is a pandas Series of image data.\n","\n","    Yields:\n","        pd.Series of image features\n","    \"\"\"\n","    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n","    # for multiple data batches.  This amortizes the overhead of loading big models.\n","    model = model_create()\n","    # Broadcast weights to workers\n","    model.set_weights(broadcast_weights.value)\n","    for content_series in content_series_iter:\n","        yield featurize_series(model, content_series)"]},{"cell_type":"markdown","metadata":{},"source":["### Load the images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load all images\n","images = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.jpg\").option(\"recursiveFileLookup\", \"true\").load(PATH_DATA)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- path: string (nullable = true)\n"," |-- modificationTime: timestamp (nullable = true)\n"," |-- length: long (nullable = true)\n"," |-- content: binary (nullable = true)\n"," |-- label: string (nullable = true)\n","\n","None\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------------------+-----------+\n","|path                                                                                     |label      |\n","+-----------------------------------------------------------------------------------------+-----------+\n","|file:/Users/victor/Documents/OPENCLASSROOMS/projet_8/data/training/apple_hit_1/r0_116.jpg|apple_hit_1|\n","|file:/Users/victor/Documents/OPENCLASSROOMS/projet_8/data/training/apple_hit_1/r0_114.jpg|apple_hit_1|\n","|file:/Users/victor/Documents/OPENCLASSROOMS/projet_8/data/training/apple_hit_1/r0_108.jpg|apple_hit_1|\n","|file:/Users/victor/Documents/OPENCLASSROOMS/projet_8/data/training/apple_hit_1/r0_118.jpg|apple_hit_1|\n","|file:/Users/victor/Documents/OPENCLASSROOMS/projet_8/data/training/apple_hit_1/r0_120.jpg|apple_hit_1|\n","+-----------------------------------------------------------------------------------------+-----------+\n","only showing top 5 rows\n","\n","None\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 1:==================================================>    (179 + 1) / 195]\r"]},{"name":"stdout","output_type":"stream","text":["Number of images loaded :  6231\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Display first images\n","images = images.withColumn('label', F.element_at(F.split(images['path'], '/'),-2))\n","print(images.printSchema())\n","print(images.select('path','label').show(5,False))\n","print(\"Number of images loaded : \", images.count())"]},{"cell_type":"markdown","metadata":{},"source":["### Run the model inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Select 10% of dataset for local test\n","images_sample = images.sample(fraction=0.1, seed=42)\n","display(images_sample.show(5))\n","display(images_sample.printSchema())\n","print(\"Number of images : \", images_sample.count())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-03-08 15:40:56.922692: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"]},{"name":"stdout","output_type":"stream","text":["+--------------------+-----------+--------------------+--------------------+\n","|                path|      label|            features|        features_vec|\n","+--------------------+-----------+--------------------+--------------------+\n","|file:/Users/victo...|apple_hit_1|[0.3222898, 0.459...|[0.32228979468345...|\n","|file:/Users/victo...|apple_hit_1|[1.1753603, 0.059...|[1.17536032199859...|\n","|file:/Users/victo...| cucumber_3|[1.5150166, 0.201...|[1.51501655578613...|\n","|file:/Users/victo...|apple_red_3|[0.5331319, 0.003...|[0.53313189744949...|\n","|file:/Users/victo...|     pear_3|[0.6971466, 0.223...|[0.69714659452438...|\n","+--------------------+-----------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["root\n"," |-- path: string (nullable = true)\n"," |-- label: string (nullable = true)\n"," |-- features: array (nullable = true)\n"," |    |-- element: float (containsNull = true)\n"," |-- features_vec: vector (nullable = true)\n","\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["23/03/08 23:02:22 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 918965 ms exceeds timeout 120000 ms\n","23/03/08 23:02:22 WARN SparkContext: Killing executors is not supported by current scheduler.\n","23/03/08 23:02:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:02:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:02:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:02:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:02:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:02:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:03:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:03:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:18:32 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:18:32 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:18:42 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:18:42 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:18:53 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:18:53 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:19:02 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:19:02 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:19:12 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:19:12 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:34:49 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:34:49 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:34:59 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:34:59 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:35:09 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:35:09 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:35:19 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:35:19 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:35:29 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:35:29 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:51:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:51:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:52:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/08 23:52:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/08 23:52:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:06 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:06 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:16 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:16 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:26 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:26 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:36 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:36 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:46 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:46 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:08:56 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:08:56 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:26:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:26:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:27:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:27:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:27:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:28:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:28:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:28:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:29:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:29:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:29:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:29:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:29:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:29:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:30:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:30:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:30:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:30:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:30:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:31:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:31:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","23/03/09 00:31:17 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:17 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:27 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:27 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n","\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@nc-ass-vip.sdv.fr:58791\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 19 more\n","23/03/09 00:31:47 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------\n","Exception occurred during processing of request from ('127.0.0.1', 58816)\n","Traceback (most recent call last):\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n","    self.process_request(request, client_address)\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/socketserver.py\", line 347, in process_request\n","    self.finish_request(request, client_address)\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/socketserver.py\", line 360, in finish_request\n","    self.RequestHandlerClass(request, client_address, self)\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/socketserver.py\", line 747, in __init__\n","    self.handle()\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/site-packages/pyspark/accumulators.py\", line 281, in handle\n","    poll(accum_updates)\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/site-packages/pyspark/accumulators.py\", line 253, in poll\n","    if func():\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n","    num_updates = read_int(self.rfile)\n","  File \"/Users/victor/miniconda3/envs/openclassrooms/lib/python3.10/site-packages/pyspark/serializers.py\", line 595, in read_int\n","    raise EOFError\n","EOFError\n","----------------------------------------\n"]}],"source":["# Create the image features\n","features_df = images_sample.repartition(20).select(F.col(\"path\"), F.col(\"label\"),\n","                                                   featurize_udf(\"content\").alias('features'))\n","\n","# Create the vectors\n","features_df = features_df.withColumn('features_vec', array_to_vector(\"features\"))\n","\n","display(features_df.show(5))\n","display(features_df.printSchema())"]},{"cell_type":"markdown","metadata":{},"source":["# Dimension reduction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Number of components\n","PCA_K = 100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["23/03/08 13:05:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\n","java.io.IOException: Connecting to nc-ass-vip.sdv.fr/212.95.74.75:56997 failed in the last 4750 ms, fail this connection directly\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n","\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:126)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","23/03/08 13:05:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\n","java.io.IOException: Connecting to nc-ass-vip.sdv.fr/212.95.74.75:56997 failed in the last 4750 ms, fail this connection directly\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n","\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:126)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","23/03/08 13:05:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\n","java.io.IOException: Connecting to nc-ass-vip.sdv.fr/212.95.74.75:56997 failed in the last 4750 ms, fail this connection directly\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n","\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:126)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","23/03/08 13:05:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\n","java.io.IOException: Failed to connect to nc-ass-vip.sdv.fr/212.95.74.75:56997\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n","\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:126)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)\n","\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: nc-ass-vip.sdv.fr/212.95.74.75:56997\n","Caused by: java.net.ConnectException: Operation timed out\n","\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:715)\n","\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n","\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:710)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n","\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\tat java.lang.Thread.run(Thread.java:750)\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 27:>                                                         (0 + 4) / 4]\r"]}],"source":["# Create pyspark PCA model\n","pca = pyPCA(k=PCA_K, inputCol='features_vec', outputCol='features_pca')\n","\n","# Fit model\n","pca_model = pca.fit(features_df)\n","\n","# Transform data\n","pca_data = pca_model.transform(features_df)\n","\n","display(features_df.show(5))\n","display(features_df.printSchema())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save results as parquet files\n","features_df.write.mode(\"overwrite\").parquet(PATH_RESULTS)"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"dcaaa7a9d183f459d4e465c07043dbad484a0558a90dd2447d0bcf4ac8fcf6e2"}}},"nbformat":4,"nbformat_minor":4}
