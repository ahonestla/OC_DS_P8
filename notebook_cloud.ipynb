{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Set up"]},{"cell_type":"markdown","metadata":{},"source":["Python librairies imports :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# File system management\n","import io\n","\n","# Data manipulation\n","import numpy as np\n","import pandas as pd\n","from typing import Iterator\n","\n","# Image manipulation\n","from PIL import Image\n","\n","# Tensorflow\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras import Model\n","\n","# Pyspark\n","from pyspark.ml.feature import PCA as pyPCA\n","from pyspark.ml.functions import array_to_vector, vector_to_array\n","from pyspark.sql import functions as F\n","# from pyspark.sql import SparkSession"]},{"cell_type":"markdown","metadata":{},"source":["Define work location :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Current project path\n","PATH_PROJ = \"gs://bucket-openclassrooms-p8\"\n","\n","\n","# Define images paths\n","PATH_DATA = PATH_PROJ + \"/data/test\"\n","PATH_RESULTS = PATH_PROJ + \"/data/results\""]},{"cell_type":"markdown","metadata":{},"source":["# Data processing"]},{"cell_type":"markdown","metadata":{},"source":["## Functions"]},{"cell_type":"markdown","metadata":{},"source":["### MobileNetV2 model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model_create(show_summary=False):\n","    \"\"\"Create a MobileNetV2 model with top layer removed\n","\n","    Returns:\n","        MobileNetV2 model\n","    \"\"\"\n","    # Load default model\n","    model_base = MobileNetV2(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n","\n","    # Freeze layers\n","    for layer in model_base.layers:\n","        layer.trainable = False\n","\n","    # Create model without top layer\n","    model_new = Model(inputs=model_base.input, outputs=model_base.layers[-2].output)\n","\n","    # Show model summary\n","    if show_summary is True:\n","        print(model_new.summary())\n","\n","    return model_new"]},{"cell_type":"markdown","metadata":{},"source":["### Images preprocesssing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(content):\n","    \"\"\"Preprocesses raw image bytes.\n","\n","    Args:\n","        content: PIL Image\n","\n","    Returns:\n","        Numpy array\n","    \"\"\"\n","    img = Image.open(io.BytesIO(content)).resize([224, 224])\n","    arr = img_to_array(img)\n","    return preprocess_input(arr)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def featurize_series(model, content_series):\n","    \"\"\"Featurize a pd.Series of raw images using the input model.\n","\n","    Args:\n","        model: CNN model\n","        content_series: pd.Series of image data\n","\n","    Returns:\n","        pd.Series of image features\n","    \"\"\"\n","    content_input = np.stack(content_series.map(preprocess))\n","    preds = model.predict(content_input)\n","    # For some layers, output features will be multi-dimensional tensors.\n","    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n","    output = [p.flatten() for p in preds]\n","    return pd.Series(output)"]},{"cell_type":"markdown","metadata":{},"source":["## Distributed model inference"]},{"cell_type":"markdown","metadata":{},"source":["### Create the Spark session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Spark session created by cloud notebook\n","\n","# Create sparkContext\n","sc = spark.sparkContext\n","\n","# Set log level\n","sc.setLogLevel(\"WARN\")\n","\n","spark"]},{"cell_type":"markdown","metadata":{},"source":["### Broadcast the model weights"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create broadcast weights\n","broadcast_weights = spark.sparkContext.broadcast(model_create(show_summary=True).get_weights())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@F.pandas_udf(\"array<float>\")\n","def featurize_udf(content_series_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n","    \"\"\"This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n","        The decorator specifies this returns a Spark DataFrame column of type ArrayType(FloatType).\n","\n","    Args:\n","        content_series_iter: Iterator over batches of data, where each batch\n","                            is a pandas Series of image data.\n","\n","    Yields:\n","        pd.Series of image features\n","    \"\"\"\n","    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n","    # for multiple data batches.  This amortizes the overhead of loading big models.\n","    model = model_create()\n","    # Broadcast weights to workers\n","    model.set_weights(broadcast_weights.value)\n","    for content_series in content_series_iter:\n","        yield featurize_series(model, content_series)"]},{"cell_type":"markdown","metadata":{},"source":["### Load the images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load all images\n","images = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.jpg\").option(\"recursiveFileLookup\", \"true\").load(PATH_DATA)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Display first images\n","images = images.withColumn('label', F.element_at(F.split(images['path'], '/'),-2))\n","print(images.printSchema())\n","print(images.select('path','label').show(5, False))\n","print(\"Number of images loaded : \", images.count())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Select sample of dataset\n","SELECT_RATIO = 0.1\n","images = images.sample(fraction=SELECT_RATIO, seed=42)\n","print(\"Select {0:.0%} of images : {0}\".format(SELECT_RATIO, images.count()))"]},{"cell_type":"markdown","metadata":{},"source":["### Run the model inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the image features\n","features_df = images.select(F.col(\"path\"), F.col(\"label\"),\n","                                                   featurize_udf(\"content\").alias('features'))\n","\n","# Create the vectors\n","features_df = features_df.withColumn('features_vec', array_to_vector(\"features\"))\n","\n","display(features_df.show(5))\n","display(features_df.printSchema())"]},{"cell_type":"markdown","metadata":{},"source":["# Dimension reduction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Number of components\n","PCA_K = 166"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create pyspark PCA model\n","pca = pyPCA(k=PCA_K, inputCol='features_vec', outputCol='features_pca')\n","\n","# Fit model\n","pca_model = pca.fit(features_df)\n","\n","# Transform data\n","features_df = pca_model.transform(features_df)\n","\n","display(features_df.show(5))\n","display(features_df.printSchema())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Export results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save results as parquet files\n","features_df.write.mode(\"overwrite\").parquet(PATH_RESULTS + \"/Features_output\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save PCA output as single json file\n","features_df.select(F.col('features_pca')).withColumn('features_pca', vector_to_array('features_pca')) \\\n","    .repartition(1) \\\n","    .write \\\n","    .mode(\"overwrite\") \\\n","    .json(PATH_RESULTS + \"/PCA_output\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"dcaaa7a9d183f459d4e465c07043dbad484a0558a90dd2447d0bcf4ac8fcf6e2"}}},"nbformat":4,"nbformat_minor":4}
